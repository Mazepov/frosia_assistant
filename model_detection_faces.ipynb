{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYifCLoxrXhq"
      },
      "outputs": [],
      "source": [
        "#Загрузим необходимые библиотеки\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "import cv2\n",
        "from imageio import imread\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "from livelossplot.tf_keras import PlotLossesCallback"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Настройка пути с датасетом\n",
        "dir_path = '.'\n",
        "\n",
        "#Здесь должны быть фото по папкам\n",
        "base_dir = Path(dir_path + '/train')"
      ],
      "metadata": {
        "id": "Qe6q5cYirYk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Зададим размер batch и размер изображения\n",
        "BATCH_SIZE = 64\n",
        "IMG_SHAPE  = 224\n",
        "\n",
        "#Создадим необходимые train (80%) и validation (20%) datasets\n",
        "#Зададим некоторые параметры аугментации\n",
        "\n",
        "data_image_gen = ImageDataGenerator(\n",
        "                                    preprocessing_function=preprocess_input,\n",
        "#                                     rescale=1./255,\n",
        "                                    rotation_range=40, #Добавить поворот\n",
        "                                    shear_range=0.2, #Добавить сдвиг\n",
        "                                    zoom_range=0.2, #Добавить увеличение\n",
        "                                    horizontal_flip=True, #Добавить зеркальный поворот\n",
        "                                    fill_mode=\"nearest\", #Заполняем пробелы\n",
        "                                    validation_split=0.2)\n",
        "\n",
        "train_data = data_image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                directory=base_dir,\n",
        "                                                shuffle=True,\n",
        "                                                target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='training')\n",
        "\n",
        "valid_data = data_image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                directory=base_dir,\n",
        "                                                shuffle=True,\n",
        "                                                target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='validation')"
      ],
      "metadata": {
        "id": "GrIE9QRDrl33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Изображения и лэйблы\n",
        "train_images, train_labels = next(train_data)\n",
        "val_images, val_labels = next(valid_data)\n",
        "\n",
        "#Количество людей для распознавания\n",
        "n_faces = train_labels.shape[1]"
      ],
      "metadata": {
        "id": "tf5xlR6Krl1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Модель\n",
        "model_VGGFace = tf.keras.Sequential([tf.keras.layers.ZeroPadding2D((1,1),input_shape=(224,224, 3)),\n",
        "                                           tf.keras.layers.Convolution2D(64, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.ZeroPadding2D((1,1)),\n",
        "                                           tf.keras.layers.Convolution2D(64, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)),\n",
        "\n",
        "                                           tf.keras.layers.ZeroPadding2D((1,1)),\n",
        "                                           tf.keras.layers.Convolution2D(128, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.ZeroPadding2D((1,1)),\n",
        "                                           tf.keras.layers.Convolution2D(128, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)),\n",
        "\n",
        "                                           tf.keras.layers.ZeroPadding2D((1,1)),\n",
        "                                           tf.keras.layers.Convolution2D(256, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.ZeroPadding2D((1,1)),\n",
        "                                           tf.keras.layers.Convolution2D(256, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.ZeroPadding2D((1,1)),\n",
        "                                           tf.keras.layers.Convolution2D(256, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)),\n",
        "\n",
        "                                           tf.keras.layers.ZeroPadding2D((1,1)),\n",
        "                                           tf.keras.layers.Convolution2D(512, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.ZeroPadding2D((1,1)),\n",
        "                                           tf.keras.layers.Convolution2D(512, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.ZeroPadding2D((1,1)),\n",
        "                                           tf.keras.layers.Convolution2D(512, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)),\n",
        "\n",
        "\n",
        "                                           tf.keras.layers.ZeroPadding2D((1,1)),\n",
        "                                           tf.keras.layers.Convolution2D(512, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.ZeroPadding2D((1,1)),\n",
        "                                           tf.keras.layers.Convolution2D(512, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.ZeroPadding2D((1,1)),\n",
        "                                           tf.keras.layers.Convolution2D(512, (3, 3), activation='relu'),\n",
        "                                           tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)),\n",
        "\n",
        "                                           tf.keras.layers.Convolution2D(4096, (7, 7), activation='relu'),\n",
        "                                           tf.keras.layers.Dropout(0.5),\n",
        "                                           tf.keras.layers.Convolution2D(4096, (1, 1), activation='relu'),\n",
        "                                           tf.keras.layers.Dropout(0.5),\n",
        "                                           tf.keras.layers.Convolution2D(2622, (1, 1)),\n",
        "\n",
        "                                           tf.keras.layers.Flatten()])\n",
        "\n",
        "#загрузим веса VGGFace\n",
        "model_VGGFace.load_weights(dir_path + '/vgg_face_weights.h5')\n",
        "\n",
        "#Посмотрим на структуру  модели\n",
        "model_VGGFace.summary()"
      ],
      "metadata": {
        "id": "mxsk_HhBrlyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Возьмём только основную часть модели до слоя\n",
        "\n",
        "model_base_VGGFace = tf.keras.Model([model_VGGFace.input],\n",
        "                                    model_VGGFace.get_layer('flatten').output)\n",
        "\n",
        "#Заморозим базовую модель (так веса модели сформированы датасетом VGGFace)\n",
        "#Если веса imagenet, то все слои разморозить (=True)\n",
        "model_base_VGGFace.trainable = True"
      ],
      "metadata": {
        "id": "mwxtQyaPr8c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Допишем модель\n",
        "faces_model_base_VGGFace = tf.keras.Sequential([model_base_VGGFace,\n",
        "                                                  tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                                  tf.keras.layers.Dense(n_faces, activation='softmax')])"
      ],
      "metadata": {
        "id": "b9TTVl8dr8Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Параметры модели\n",
        "optim = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "metric = tf.keras.metrics.categorical_accuracy\n",
        "\n",
        "#Компиляция\n",
        "faces_model_base_VGGFace.compile(optimizer=optim, loss=loss, metrics=metric)"
      ],
      "metadata": {
        "id": "1f34HAaWr8XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Сохраним наилучший результат модели\n",
        "# model_best_path = Path(dir_path + '/model_best_VGGFace')\n",
        "# model_best_path.mkdir(exist_ok=True)\n",
        "# model_best_filename = 'checkpoint_best.h5'\n",
        "# model_best_path_total = str(model_best_path/model_best_filename)\n",
        "# checkpoint = tf.keras.callbacks.ModelCheckpoint(model_best_path_total,\n",
        "#                                                 monitor='val_accuracy',\n",
        "#                                                 verbose=1,\n",
        "#                                                 save_best_only=True,\n",
        "#                                                 mode='max')"
      ],
      "metadata": {
        "id": "yI6q3V1zr8US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Обучение\n",
        "\n",
        "EPOCHS = 5\n",
        "history = faces_model_base_VGGFace.fit(train_data,\n",
        "                                         validation_data=valid_data,\n",
        "                                         epochs=EPOCHS,\n",
        "                                         callbacks=[PlotLossesCallback()])"
      ],
      "metadata": {
        "id": "OebK34LWsmRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Сохраним модель\n",
        "faces_model_base_VGGFace.save(dir_path + '/checkpoint_best_2.h5')"
      ],
      "metadata": {
        "id": "_h8x2hIAsmOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6IAoOZrcsmMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "djvXCMVJsmJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N33RHtNEsmGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bEedA097r8RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2asRT6xrYfJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}